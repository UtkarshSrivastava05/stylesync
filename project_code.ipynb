{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wtFQhTsmw-w",
        "outputId": "043d7013-f3ac-41d1-8b26-02261c40e4f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylesync'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 41 (delta 14), reused 30 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (41/41), 33.14 KiB | 16.57 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/UtkarshSrivastava05/stylesync.git\n",
        "# !pip install -qq -U diffusers==0.11.1 transformers ftfy gradio accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W38dI6ltRi9o",
        "outputId": "fec4850e-d9d0-4657-d031-6926a0db6445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: asyncio in /usr/local/lib/python3.10/dist-packages (3.4.3)\n"
          ]
        }
      ],
      "source": [
        "# !pip install asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LMzk3_3-try1"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import torch\n",
        "import cv2\n",
        "# import gradio as gr\n",
        "import numpy as np\n",
        "# from diffusers import StableDiffusionInpaintPipeline\n",
        "# from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from flask import Flask, request, jsonify, render_template, session, redirect, url_for\n",
        "from werkzeug.utils import secure_filename\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTWJ5wnFRqIm"
      },
      "outputs": [],
      "source": [
        "# import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YPYUrsAuSSFj",
        "outputId": "2e412ad5-f484-4e74-8fa2-5d73408ed520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://jb7qh4q3du-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ]
        }
      ],
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifj0Oo1pULVL",
        "outputId": "1d4c901c-0d3a-4f52-c6d9-35fd3e73967e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Feb/2024 17:01:23] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Feb/2024 17:01:24] \"GET /static/css/style.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Feb/2024 17:01:24] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Feb/2024 17:01:37] \"POST /process_form HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_url:  /static/dress.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [26/Feb/2024 17:01:37] \"GET /static/Loading_icon.gif HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image:  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=687x1200 at 0x7C07B1D60DC0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [26/Feb/2024 17:01:47] \"GET /generate?image_url=/static/dress.jpg&text=apni+to+pathsahal HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Feb/2024 17:01:48] \"GET /static/dress.jpg HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Feb/2024 17:01:49] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request, redirect, flash\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Additional libraries/functions (optional)\n",
        "import uuid\n",
        "from werkzeug.utils import secure_filename\n",
        "allowed_extensions = ['jpg', 'jpeg', 'png', 'gif']  # List of allowed image extensions\n",
        "\n",
        "\n",
        "app = Flask(__name__,\n",
        "            template_folder='/content/stylesync/templates',\n",
        "            static_folder='/content/stylesync/static'\n",
        "      )\n",
        "app.config['UPLOAD_FOLDER'] = 'stylesync/static'  # Configure upload directory\n",
        "app.config['STATIC_FOLDER'] = 'stylesync/static'\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "  return render_template('form.html')  # Replace 'form.html' with your template name\n",
        "\n",
        "\n",
        "@app.route('/process_form', methods=['POST'])\n",
        "def process_form():\n",
        "  text = request.form['text_input']\n",
        "  photo = request.files['photo_upload']\n",
        "\n",
        "  # Validate file extension\n",
        "  if photo.filename and photo.filename.rsplit('.', 1)[1].lower() not in allowed_extensions:\n",
        "    flash('Allowed image types: jpg, jpeg, png, gif', 'error')\n",
        "    return redirect(url_for('index'))\n",
        "\n",
        "  # Save the photo with a secure filename\n",
        "  filename = secure_filename(photo.filename)\n",
        "  photo.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "\n",
        "  # Generate the complete image URL (add static route)\n",
        "  image_url = url_for('static', filename=filename)\n",
        "  print(\"image_url: \", image_url)\n",
        "\n",
        "  return render_template('loading_2.html', text=text, image_url=image_url)\n",
        "\n",
        "  # return render_template('redirect_message.html', text=text, image_url=image_url)\n",
        "\n",
        "@app.route('/generate')\n",
        "def generate():\n",
        "    text = request.args.get('text')\n",
        "\n",
        "    image_url = request.args.get('image_url')\n",
        "\n",
        "    # Get the full file path from the image URL\n",
        "    image_path = os.path.join(app.config['STATIC_FOLDER'], image_url.split('/')[-1])  # Extract filename from URL\n",
        "\n",
        "    # Open the image file for reading (replace with your processing logic)\n",
        "    with open(image_path, 'rb') as f:\n",
        "        image_data = f.read()\n",
        "\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    print(\"image: \", image)\n",
        "\n",
        "    time.sleep(10)\n",
        "\n",
        "    # Display the image using the URL\n",
        "    return f'<img src=\"{image_url}\" alt=\"Processed Image\">'\n",
        "    # return render_template('loading_2.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXP1vOdruy7p",
        "outputId": "f541d63f-c924-479c-ce20-924062923063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "app = Flask(__name__,\n",
        "            template_folder='/content/stylesync/templates',\n",
        "            static_folder='/content/stylesync/static'\n",
        "      )\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"index_new.html\")\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    # redirect(\"/loading_page\")\n",
        "\n",
        "    print(\"Hello There!\")\n",
        "    # Access the uploaded file and prompt from the request\n",
        "    photo = request.files['photo']\n",
        "    prompt = request.form['text_prompt']\n",
        "\n",
        "    print('prompt first', prompt)\n",
        "    print('photo: ', photo)\n",
        "\n",
        "    # return redirect(url_for('loading', photo_url=photo, prompt_value=prompt))\n",
        "    # return redirect(url_for(\"loading\", prompt=prompt, photo=photo))\n",
        "    # Store data in session\n",
        "    # session['data_to_pass'] = prompt\n",
        "    return redirect(url_for('loading', data=prompt))\n",
        "\n",
        "    # return jsonify({\"message\": \"Data received successfully!\"})\n",
        "    # return render_template(\"loading.html\")\n",
        "    # return render_template(\"result.html\")\n",
        "\n",
        "# Add routes for the loading and result pages\n",
        "\n",
        "@app.route('/loading', methods=['POST', 'GET'])\n",
        "def loading():\n",
        "    print(\"Inside loading function\")\n",
        "\n",
        "    received_data = request.args.get('data')\n",
        "    print(\"received_data: \", received_data)\n",
        "    prompt = received_data\n",
        "\n",
        "    # photo = request.files['photo']\n",
        "    # filename = secure_filename(photo.filename)  # Securely access filename\n",
        "    # photo.save(filename)  # Save the file temporarily\n",
        "\n",
        "    # prompt = request.form['text_prompt']\n",
        "    # prompt = \"Kuch to hai prompt re baba\"\n",
        "\n",
        "    # print(\"photo_url: \", photo)\n",
        "    # print(\"filename: \", filename)\n",
        "    # print(\"prompt_value: \", prompt)\n",
        "    # Example data to pass to the template\n",
        "    additional_data = \"Some additional data\"\n",
        "\n",
        "    # Pass the data to the template\n",
        "    return render_template(\"loading.html\", prompt=prompt, additional_data=additional_data)\n",
        "\n",
        "@app.route('/result')\n",
        "def result():\n",
        "    # You may need to pass dynamic data to the result template, e.g., image path\n",
        "    image_path = url_for('static', filename='white_tshirt.jpg')\n",
        "    return render_template(\"result.html\", image_path=image_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEZVfwi6Sox8",
        "outputId": "6080b588-325b-4447-936a-7c6aabc7cf55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Feb/2024 17:11:19] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Feb/2024 17:11:20] \"GET /static/css/style.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Feb/2024 17:11:21] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "ERROR:__main__:Exception on /generate [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-5-a13984aea2c6>\", line 93, in generate\n",
            "    found_index = find_original_index(prompt, id2label, cloth_mapping)\n",
            "NameError: name 'find_original_index' is not defined\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Feb/2024 17:11:27] \"\u001b[35m\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello There!\n",
            "prompt first Haila Haila\n",
            "type of photo <class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
            "photo printing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=564x685 at 0x7ACDF6367D60>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Exception on /generate [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-5-a13984aea2c6>\", line 93, in generate\n",
            "    found_index = find_original_index(prompt, id2label, cloth_mapping)\n",
            "NameError: name 'find_original_index' is not defined\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Feb/2024 17:11:32] \"\u001b[35m\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello There!\n",
            "prompt first Haila Haila\n",
            "type of photo <class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
            "photo printing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=564x685 at 0x7ACDF6498490>\n"
          ]
        }
      ],
      "source": [
        "# Set the device\n",
        "device = \"cuda\"\n",
        "# device = \"cpu\"\n",
        "\n",
        "# model_path = \"runwayml/stable-diffusion-inpainting\"\n",
        "\n",
        "# # Load the stable diffusion model\n",
        "# pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "#     model_path,\n",
        "#     torch_dtype=torch.float16,\n",
        "# ).to(device)\n",
        "\n",
        "# # Load image processing model for semantic segmentation\n",
        "# processor = SegformerImageProcessor.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")\n",
        "# model = AutoModelForSemanticSegmentation.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")\n",
        "\n",
        "# # Define label mappings for clothing items\n",
        "# id2label = model.config.id2label\n",
        "# cloth_mapping = {\n",
        "#     'Upper-clothes': ['tshirt', 'shirt', 'top', 'top wear', 'jacket', 'crop top',\n",
        "#                       'sweater', 'cardigan', 'sweatshirt', 'hoodie', 'kurta'],\n",
        "#     'Pants': ['pant', 'trouser', 'jeans', 'leggings'],\n",
        "#     'Dress': ['dress', 'frock', 'one piece', 'long coat', 'jumpsuit']\n",
        "# }\n",
        "\n",
        "# # Function to find the original index based on text prompt and label mappings\n",
        "# def find_original_index(text_prompt, id2label, cloth_mapping):\n",
        "#     for index, label in id2label.items():\n",
        "#         if label in list(cloth_mapping.keys()):\n",
        "#             if any(word in text_prompt.lower() for word in cloth_mapping[label]):\n",
        "#                 return index\n",
        "#     return None\n",
        "\n",
        "app = Flask(__name__,\n",
        "            template_folder='/content/stylesync/templates',\n",
        "            static_folder='/content/stylesync/static'\n",
        "      )\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"index_new.html\")\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    redirect(\"/loading_page\")\n",
        "\n",
        "    print(\"Hello There!\")\n",
        "    # Access the uploaded file and prompt from the request\n",
        "    photo = request.files['photo']\n",
        "    prompt = request.form['text_prompt']\n",
        "\n",
        "    print('prompt first',prompt)\n",
        "\n",
        "    # Redirect to the loading page while processing\n",
        "    # return render_template(\"loading.html\")\n",
        "\n",
        "    if photo:\n",
        "        # Save the uploaded file to a temporary location\n",
        "        filename = secure_filename(photo.filename)\n",
        "        file_path = os.path.join('/', filename)\n",
        "        photo.save(file_path)\n",
        "\n",
        "        # Open the file using PIL\n",
        "        image = Image.open(file_path)\n",
        "\n",
        "        # Now you can perform any operations on the image using PIL\n",
        "        # For example, you can display it\n",
        "        # image.show()\n",
        "    print('type of photo',type(image))\n",
        "    print('photo printing',image)\n",
        "\n",
        "    # Sample text prompt\n",
        "    # prompt = \"Change the shirt to a black kurta, with the Spider-Man on it.\"\n",
        "    # prompt = request.form('text_prompt')\n",
        "    # print('prompt first',prompt)\n",
        "\n",
        "    # if 'photo' in request.files:\n",
        "    #     image = request.files['photo']\n",
        "\n",
        "\n",
        "    # f = request.files['file']\n",
        "\n",
        "    # # Save the file to ./uploads\n",
        "    # basepath = os.path.dirname(_file_)\n",
        "    # file_path = os.path.join(\n",
        "    #     basepath, 'uploads', secure_filename(f.filename))\n",
        "    # f.save(file_path)\n",
        "\n",
        "    # print('prompt',prompt)\n",
        "    # print('image',image)\n",
        "\n",
        "    # # Find the original index based on the prompt\n",
        "    found_index = find_original_index(prompt, id2label, cloth_mapping)\n",
        "\n",
        "    if found_index is not None:\n",
        "        print(f\"Original Index found: {found_index}, Label: {id2label[found_index]}\")\n",
        "    else:\n",
        "        print(\"No matching label found.\")\n",
        "\n",
        "    # # Assuming label number 4 is the label you're interested in\n",
        "    desired_label = found_index\n",
        "\n",
        "    # Read and preprocess the image\n",
        "    IMAGE_PATH = file_path\n",
        "\n",
        "    image = cv2.imread(IMAGE_PATH)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    org_img_size = image.shape[0:2]\n",
        "    image = Image.fromarray(image)\n",
        "\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits.cpu()\n",
        "\n",
        "    upsampled_logits = nn.functional.interpolate(\n",
        "        logits,\n",
        "        size=image.size[::-1],\n",
        "        mode=\"bilinear\",\n",
        "        align_corners=False,\n",
        "    )\n",
        "\n",
        "    pred_seg = upsampled_logits.argmax(dim=1)[0]\n",
        "\n",
        "    # Create a binary mask for the desired label\n",
        "    mask = np.array(pred_seg == desired_label, dtype=np.uint8)\n",
        "\n",
        "    # Convert binary mask to binary gray (0 or 255)\n",
        "    binary_gray_mask = (mask * 255).astype(np.uint8)\n",
        "\n",
        "    # Create a PIL Image from the binary gray mask\n",
        "    pil_mask = Image.fromarray(binary_gray_mask, mode='L')\n",
        "\n",
        "    # Resize images for processing\n",
        "    image = image.resize((512, 512))\n",
        "    mask_image = pil_mask.resize((512, 512))\n",
        "\n",
        "    # Set parameters for outfit generation\n",
        "    guidance_scale = 7.5\n",
        "    num_samples = 3\n",
        "    generator = torch.Generator(device=\"cuda\").manual_seed(42)\n",
        "\n",
        "    # # Generate new outfits based on the prompt and input images\n",
        "    # images = pipe(\n",
        "    #     prompt=prompt,\n",
        "    #     image=image,\n",
        "    #     mask_image=mask_image,\n",
        "    #     guidance_scale=guidance_scale,\n",
        "    #     generator=generator,\n",
        "    #     num_images_per_prompt=num_samples,\n",
        "    # ).images\n",
        "\n",
        "    # # Resize generated images to the original image size\n",
        "    # for i in range(len(images)):\n",
        "    #     images[i] = images[i].resize(tuple(reversed(org_img_size)))\n",
        "\n",
        "    # # Display the image grid\n",
        "    # generated_images = image_grid(images, 1, num_samples + 1)\n",
        "\n",
        "    # Redirect to the result page\n",
        "    return render_template(\"result.html\")\n",
        "\n",
        "\n",
        "    return jsonify({'status': 'success', 'message': 'Image and prompt received successfully'})\n",
        "\n",
        "# @app.route('/upload_image',methods=['POST'])\n",
        "# def upload_image():\n",
        "#     # Get the uploaded file\n",
        "#     uploaded_file = request.files['image']\n",
        "\n",
        "#     return render_template('index_new.html', prediction_text='Employee image should be $ {}'.format(output))\n",
        "\n",
        "\n",
        "# @app.route('/predict_api',methods=['POST'])\n",
        "# def predict_api():\n",
        "#     '''\n",
        "#     For direct API calls trought request\n",
        "#     '''\n",
        "#     data = request.get_json(force=True)\n",
        "#     prediction = model.predict([np.array(list(data.values()))])\n",
        "\n",
        "#     output = prediction[0]\n",
        "#     return jsonify(output)\n",
        "\n",
        "# Add routes for the loading and result pages\n",
        "\n",
        "@app.route('/loading_page', methods=['POST'])\n",
        "def loading():\n",
        "    return render_template(\"loading.html\")\n",
        "\n",
        "@app.route('/result')\n",
        "def result():\n",
        "    # You may need to pass dynamic data to the result template, e.g., image path\n",
        "    image_path = url_for('static', filename='white_tshirt.jpg')\n",
        "    return render_template(\"result.html\", image_path=image_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}